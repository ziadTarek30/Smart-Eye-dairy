{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10682100,"sourceType":"datasetVersion","datasetId":6617691},{"sourceId":10682111,"sourceType":"datasetVersion","datasetId":6617700},{"sourceId":10682465,"sourceType":"datasetVersion","datasetId":6617983},{"sourceId":10696946,"sourceType":"datasetVersion","datasetId":6628592},{"sourceId":10882097,"sourceType":"datasetVersion","datasetId":6761825},{"sourceId":10882345,"sourceType":"datasetVersion","datasetId":6761997},{"sourceId":10908811,"sourceType":"datasetVersion","datasetId":6780846},{"sourceId":10979369,"sourceType":"datasetVersion","datasetId":6832460},{"sourceId":11007658,"sourceType":"datasetVersion","datasetId":6852894},{"sourceId":11007924,"sourceType":"datasetVersion","datasetId":6853084},{"sourceId":11020288,"sourceType":"datasetVersion","datasetId":6862161}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install  ultralytics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T21:37:15.763941Z","iopub.execute_input":"2025-03-31T21:37:15.764312Z","iopub.status.idle":"2025-03-31T21:37:19.149481Z","shell.execute_reply.started":"2025-03-31T21:37:15.764280Z","shell.execute_reply":"2025-03-31T21:37:19.148416Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -q --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T21:37:19.150911Z","iopub.execute_input":"2025-03-31T21:37:19.151221Z","iopub.status.idle":"2025-03-31T21:37:22.679949Z","shell.execute_reply.started":"2025-03-31T21:37:19.151195Z","shell.execute_reply":"2025-03-31T21:37:22.678873Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===== IMPORTS =====\n# Core libraries\nimport os\nimport time\nfrom collections import defaultdict\nfrom datetime import datetime, timezone\nfrom typing import List, Tuple, Dict, Optional, Union  # Added Union here\nfrom dataclasses import dataclass\n\n# Computer Vision\nimport cv2\nimport numpy as np\n\n# Machine Learning\nimport torch\nfrom ultralytics import YOLO\n\n# Google Drive API\nfrom google.oauth2 import service_account\nfrom googleapiclient.discovery import build\nfrom googleapiclient.http import MediaFileUpload\n\n# Utilities\nimport json\nimport uuid","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-31T21:37:22.687593Z","iopub.execute_input":"2025-03-31T21:37:22.687811Z","iopub.status.idle":"2025-03-31T21:37:22.702973Z","shell.execute_reply.started":"2025-03-31T21:37:22.687791Z","shell.execute_reply":"2025-03-31T21:37:22.702311Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"mask, gloves , person  dataset ","metadata":{}},{"cell_type":"code","source":"# ===== CONSTANTS & CONFIGURATION =====\nclass Config:\n    # Model paths\n    CUSTOM_WEIGHTS = \"/kaggle/input/mask-gloves-preson-weights/custom-weights.pt\"\n    CAP_WEIGHTS = \"/kaggle/input/capsweights/my_weights.pt\"\n    LOGO_WEIGHTS = \"/kaggle/input/logoweights/logo.pt\"\n    \n    # Video paths\n    VIDEO_INPUT = \"/kaggle/input/testvedio1/videolong.mp4\"\n    VIDEO_OUTPUT = \"/kaggle/working/output_video3.mp4\"\n    \n    # Detection thresholds\n    PERSON_CONF = 0.4\n    LOGO_CONF = 0.5\n    CAP_CONF = 0.4\n    IOU_THRESHOLD = 0.5\n    \n    # Violation settings\n    VIOLATION_DIR = \"violations7\"\n    VIOLATION_DURATION = 2  # seconds\n    \n    # Google Drive\n    SERVICE_ACCOUNT_FILE = '/kaggle/input/upload/wide-planet-449115-b2-c6af973cadb6.json'\n    DRIVE_SCOPES = ['https://www.googleapis.com/auth/drive']\n    # Date configuration - Make this a variable you can change\n    PROCESSING_DATE = \"04/01/2025\"  # Format: MM/DD/YYYY - Change this to your desired date\n    # Or use current date by default:\n    # PROCESSING_DATE = datetime.now(timezone.utc).date().strftime(\"%m/%d/%Y\")\n\n# Initialize config\nconfig = Config()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T21:37:22.703605Z","iopub.execute_input":"2025-03-31T21:37:22.703816Z","iopub.status.idle":"2025-03-31T21:37:22.715287Z","shell.execute_reply.started":"2025-03-31T21:37:22.703798Z","shell.execute_reply":"2025-03-31T21:37:22.714608Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===== MODEL LOADING =====\ndef load_models():\n    \"\"\"Load all YOLO models with error handling\"\"\"\n    print(\"Loading models...\")\n    try:\n        custom_model = YOLO(config.CUSTOM_WEIGHTS)  # person, mask, gloves\n        cap_model = YOLO(config.CAP_WEIGHTS)       # hardhat detection\n        logo_model = YOLO(config.LOGO_WEIGHTS)     # logo detection\n        print(\"Models loaded successfully\")\n        return custom_model, cap_model, logo_model\n    except Exception as e:\n        print(f\"Error loading models: {str(e)}\")\n        raise\n\ncustom_model, cap_model, logo_model = load_models()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T21:37:22.716028Z","iopub.execute_input":"2025-03-31T21:37:22.716267Z","iopub.status.idle":"2025-03-31T21:37:22.991146Z","shell.execute_reply.started":"2025-03-31T21:37:22.716248Z","shell.execute_reply":"2025-03-31T21:37:22.990292Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"acuracy ","metadata":{}},{"cell_type":"code","source":"# ===== UTILITY FUNCTIONS =====\n@dataclass\nclass BoundingBox:\n    \"\"\"Data class for bounding box coordinates and metadata\"\"\"\n    x1: float\n    y1: float\n    x2: float\n    y2: float\n    confidence: float\n    class_id: int\n    label: str\n\ndef compute_iou(box1: Union[List[float], np.ndarray], boxes: np.ndarray) -> np.ndarray:\n    \"\"\"Calculate Intersection over Union between boxes\"\"\"\n    # Convert to numpy arrays if not already\n    box1 = np.array(box1)\n    boxes = np.array(boxes)\n    \n    # Calculate intersection coordinates\n    x1 = np.maximum(box1[0], boxes[:, 0])\n    y1 = np.maximum(box1[1], boxes[:, 1])\n    x2 = np.minimum(box1[2], boxes[:, 2])\n    y2 = np.minimum(box1[3], boxes[:, 3])\n    \n    # Compute intersection area\n    inter_area = np.maximum(0, x2 - x1) * np.maximum(0, y2 - y1)\n    \n    # Compute union area\n    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n    area2 = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n    union_area = area1 + area2 - inter_area\n    \n    # Avoid division by zero\n    return inter_area / (union_area + 1e-6)\n\ndef non_max_suppression(boxes: List[List[float]], \n                       scores: List[float], \n                       iou_threshold: float = 0.5) -> List[int]:\n    \"\"\"Apply Non-Maximum Suppression to detection boxes\"\"\"\n    if not boxes:\n        return []\n    \n    boxes_array = np.array(boxes)\n    scores_array = np.array(scores)\n    \n    # Sort by descending score\n    indices = np.argsort(scores_array)[::-1]\n    \n    keep = []\n    while indices.size > 0:\n        current = indices[0]\n        keep.append(current)\n        \n        if indices.size == 1:\n            break\n            \n        # Compute IoU between current box and remaining boxes\n        current_box = boxes_array[current]\n        remaining_boxes = boxes_array[indices[1:]]\n        ious = compute_iou(current_box, remaining_boxes)\n        \n        # Remove boxes with IoU > threshold\n        indices = indices[1:][ious <= iou_threshold]\n    \n    return keep","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T21:37:22.992004Z","iopub.execute_input":"2025-03-31T21:37:22.992337Z","iopub.status.idle":"2025-03-31T21:37:23.001596Z","shell.execute_reply.started":"2025-03-31T21:37:22.992312Z","shell.execute_reply":"2025-03-31T21:37:23.000827Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===== WORKER TRACKING =====\nclass WorkerTracker:\n    \"\"\"Track workers across frames and manage violations\"\"\"\n    def __init__(self, fps: int):\n        self.fps = fps\n        self.worker_id_counter = 0\n        self.worker_history = {}  # worker_id: last_box\n        self.violation_state = {} # worker_id: violation_data\n        \n    def assign_id(self, new_box: List[float]) -> int:\n        \"\"\"Assign new or existing worker ID based on box position\"\"\"\n        new_cx = (new_box[0] + new_box[2]) / 2\n        new_cy = (new_box[1] + new_box[3]) / 2\n        \n        for wid, last_box in self.worker_history.items():\n            last_cx = (last_box[0] + last_box[2]) / 2\n            last_cy = (last_box[1] + last_box[3]) / 2\n            if np.sqrt((new_cx - last_cx)**2 + (new_cy - last_cy)**2) < 50:\n                return wid\n                \n        self.worker_id_counter += 1\n        return self.worker_id_counter\n    \n    def update_violation(self, worker_id: int, frame_count: int, \n                        violations: set) -> bool:\n        \"\"\"Update and check if violation duration exceeds threshold\"\"\"\n        if not violations:\n            if worker_id in self.violation_state:\n                del self.violation_state[worker_id]\n            return False\n            \n        violation_key = tuple(sorted(violations))\n        \n        if worker_id not in self.violation_state:\n            self.violation_state[worker_id] = {\n                \"start_frame\": frame_count,\n                \"types\": violation_key,\n                \"saved\": False\n            }\n            return False\n            \n        duration = (frame_count - self.violation_state[worker_id][\"start_frame\"]) / self.fps\n        return duration >= config.VIOLATION_DURATION and not self.violation_state[worker_id][\"saved\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T21:37:23.003953Z","iopub.execute_input":"2025-03-31T21:37:23.004176Z","iopub.status.idle":"2025-03-31T21:37:23.016729Z","shell.execute_reply.started":"2025-03-31T21:37:23.004157Z","shell.execute_reply":"2025-03-31T21:37:23.016058Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===== VIDEO PROCESSING =====\nclass VideoProcessor:\n    \"\"\"Handle video processing pipeline\"\"\"\n    def __init__(self):\n        self.cap = cv2.VideoCapture(config.VIDEO_INPUT)\n        self.fps = int(self.cap.get(cv2.CAP_PROP_FPS))\n        self.tracker = WorkerTracker(self.fps)\n        os.makedirs(config.VIOLATION_DIR, exist_ok=True)\n        \n    def process_frame(self, frame: np.ndarray, frame_count: int) -> np.ndarray:\n        \"\"\"Process a single frame for safety violations\"\"\"\n        # Run all model predictions\n        custom_results = custom_model(frame, verbose=False)[0]\n        cap_results = cap_model(frame, verbose=False)[0]\n        logo_results = logo_model(frame, verbose=False)[0]\n        \n        # Parse detections\n        person_boxes = []\n        other_detections = []\n        logo_boxes = []\n        cap_boxes = []\n        \n        # Process custom model results (person, mask, gloves)\n        for result in custom_results.boxes.data.tolist():\n            x1, y1, x2, y2, conf, cls = result\n            label = custom_results.names[int(cls)]\n            if conf >= config.PERSON_CONF:\n                if label == \"person\":\n                    person_boxes.append((x1, y1, x2, y2, conf))\n                else:\n                    other_detections.append((x1, y1, x2, y2, label, conf))\n        \n        # Process logo detections\n        for result in logo_results.boxes.data.tolist():\n            x1, y1, x2, y2, conf, _ = result\n            if conf >= config.LOGO_CONF:\n                logo_boxes.append((x1, y1, x2, y2, conf))\n        \n        # Process hardhat detections\n        for result in cap_results.boxes.data.tolist():\n            x1, y1, x2, y2, conf, cls = result\n            if conf >= config.CAP_CONF:\n                label = cap_results.names[int(cls)]\n                if label in [\"Hardhat\", \"NO-Hardhat\"]:\n                    cap_boxes.append((x1, y1, x2, y2, label, conf))\n        \n        # Apply NMS to each detection type\n        person_boxes = self._apply_nms_to_detections(person_boxes)\n        logo_boxes = self._apply_nms_to_detections(logo_boxes)\n        cap_boxes = self._apply_nms_to_detections(cap_boxes)\n        other_detections = self._apply_nms_to_detections(other_detections)\n        \n        # Process each detected person\n        for x1, y1, x2, y2, conf in person_boxes:\n            worker_id = self._process_worker(frame, x1, y1, x2, y2, \n                                           logo_boxes, other_detections, cap_boxes, \n                                           frame_count)\n        \n        return frame\n    \n    def _apply_nms_to_detections(self, detections):\n        \"\"\"Helper method to apply NMS to a list of detections\"\"\"\n        if not detections:\n            return []\n            \n        boxes = [d[:4] for d in detections]\n        scores = [d[-1] if len(d) == 5 else d[4] for d in detections]\n        keep = non_max_suppression(boxes, scores, config.IOU_THRESHOLD)\n        return [detections[i] for i in keep]\n    \n    def _process_worker(self, frame, x1, y1, x2, y2, logo_boxes, \n                       other_detections, cap_boxes, frame_count):\n        \"\"\"Process an individual worker's violations\"\"\"\n        # Check if person has logo (is a worker)\n        is_worker = any(lx1 >= x1 and ly1 >= y1 and lx2 <= x2 and ly2 <= y2 \n                       for (lx1, ly1, lx2, ly2, _) in logo_boxes)\n        \n        if is_worker:\n            worker_id = self.tracker.assign_id((x1, y1, x2, y2))\n            self.tracker.worker_history[worker_id] = (x1, y1, x2, y2)\n            \n            # Draw worker bounding box\n            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n            cv2.putText(frame, f\"Worker {worker_id}\", (int(x1), int(y1)-10), \n                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n            \n            # Check for violations\n            violations = self._check_violations(x1, y1, x2, y2, other_detections, cap_boxes, frame)\n            \n            # Update violation state\n            if self.tracker.update_violation(worker_id, frame_count, violations):\n                self._save_violation(frame, worker_id, violations, frame_count)\n    \n    def _check_violations(self, x1, y1, x2, y2, other_detections, cap_boxes, frame):\n        \"\"\"Check for safety violations within worker's bounding box\"\"\"\n        violations = set()\n        \n        # Check mask/glove violations\n        for vx1, vy1, vx2, vy2, vlabel, _ in other_detections:\n            if vx1 >= x1 and vy1 >= y1 and vx2 <= x2 and vy2 <= y2:\n                if vlabel in [\"no-mask\", \"no-gloves\"]:\n                    violations.add(vlabel)\n                    color = (0, 0, 255)  # Red for violations\n                else:\n                    color = (0, 255, 255)  # Yellow for proper equipment\n                cv2.rectangle(frame, (int(vx1), int(vy1)), (int(vx2), int(vy2)), color, 2)\n                cv2.putText(frame, vlabel, (int(vx1), int(vy1)-10), \n                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n        \n        # Check hardhat violations\n        for cx1, cy1, cx2, cy2, clabel, _ in cap_boxes:\n            if cx1 >= x1 and cy1 >= y1 and cx2 <= x2 and cy2 <= y2:\n                if clabel == \"NO-Hardhat\":\n                    violations.add(clabel)\n                    color = (0, 0, 255)\n                else:\n                    color = (0, 255, 255)\n                cv2.rectangle(frame, (int(cx1), int(cy1)), (int(cx2), int(cy2)), color, 2)\n                cv2.putText(frame, clabel, (int(cx1), int(cy1)-10), \n                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n        \n        return violations\n    \n    def _save_violation(self, frame, worker_id, violations, frame_count):\n        \"\"\"Save violation frame to disk\"\"\"\n        violation_str = \"_\".join(sorted(violations))\n        filename = f\"violation_worker{worker_id}_{violation_str}_frame{frame_count}.jpg\"\n        filepath = os.path.join(config.VIOLATION_DIR, filename)\n        cv2.imwrite(filepath, frame)\n        self.tracker.violation_state[worker_id][\"saved\"] = True\n    \n    def process_video(self):\n        \"\"\"Main video processing loop\"\"\"\n        frame_width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n        frame_height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n        fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n        \n        # Remove the 'with' statement and manually manage the VideoWriter\n        out = cv2.VideoWriter(config.VIDEO_OUTPUT, fourcc, self.fps, \n                             (frame_width, frame_height))\n        \n        frame_count = 0\n        try:\n            while self.cap.isOpened():\n                ret, frame = self.cap.read()\n                if not ret:\n                    break\n                \n                processed_frame = self.process_frame(frame, frame_count)\n                out.write(processed_frame)\n                frame_count += 1\n        finally:\n            # Ensure resources are properly released\n            self.cap.release()\n            out.release()\n            print(f\"Processed {frame_count} frames\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T21:37:23.018312Z","iopub.execute_input":"2025-03-31T21:37:23.018506Z","iopub.status.idle":"2025-03-31T21:37:23.038767Z","shell.execute_reply.started":"2025-03-31T21:37:23.018489Z","shell.execute_reply":"2025-03-31T21:37:23.037966Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===== GOOGLE DRIVE INTEGRATION =====\nclass DriveUploader:\n    \"\"\"Handle Google Drive uploads and folder management\"\"\"\n    def __init__(self):\n        self.service = self._authenticate()\n        self.root_folder = self._get_or_create_root_folder()\n        self.metadata = self._load_metadata()\n    \n    def _authenticate(self):\n        \"\"\"Authenticate with service account credentials\"\"\"\n        creds = service_account.Credentials.from_service_account_file(\n            config.SERVICE_ACCOUNT_FILE, \n            scopes=config.DRIVE_SCOPES\n        )\n        return build('drive', 'v3', credentials=creds)\n    \n    def _get_or_create_root_folder(self):\n        \"\"\"Get or create the root violations folder\"\"\"\n        query = \"name='Safety_Violation_System1' and mimeType='application/vnd.google-apps.folder'\"\n        results = self.service.files().list(q=query, fields=\"files(id,name)\").execute()\n        \n        if results.get('files'):\n            folder = results['files'][0]\n            print(f\"Using existing folder: {folder['name']} ({folder['id']})\")\n            return folder\n        \n        folder_metadata = {\n            'name': 'Safety_Violation_System1',\n            'mimeType': 'application/vnd.google-apps.folder'\n        }\n        folder = self.service.files().create(body=folder_metadata, fields='id,name').execute()\n        print(f\"Created new folder: {folder['name']} ({folder['id']})\")\n        return folder\n    \n    def _load_metadata(self):\n        \"\"\"Load or create metadata file\"\"\"\n        query = f\"name='violation_metadata.json' and '{self.root_folder['id']}' in parents\"\n        results = self.service.files().list(q=query, fields=\"files(id)\").execute()\n        \n        if results.get('files'):\n            file_id = results['files'][0]['id']\n            request = self.service.files().get_media(fileId=file_id)\n            return json.loads(request.execute().decode('utf-8'))\n        \n        return {\n            'root_folder_id': self.root_folder['id'],\n            'date_folders': {},\n            'created_at': datetime.now(timezone.utc).isoformat()\n        }\n    \n    def _get_date_folder(self, date_str):\n        \"\"\"Get or create date-specific folder\"\"\"\n        if date_str in self.metadata['date_folders']:\n            return self.metadata['date_folders'][date_str]\n        \n        folder_name = f\"violations_{date_str}_{uuid.uuid4().hex[:8]}\"\n        folder_metadata = {\n            'name': folder_name,\n            'mimeType': 'application/vnd.google-apps.folder',\n            'parents': [self.root_folder['id']]\n        }\n        folder = self.service.files().create(body=folder_metadata, fields='id,name').execute()\n        \n        self.metadata['date_folders'][date_str] = {\n            'folder_id': folder['id'],\n            'folder_name': folder['name'],\n            'display_date': config.PROCESSING_DATE,\n            'created_at': datetime.now(timezone.utc).isoformat()\n        }\n        return self.metadata['date_folders'][date_str]\n    \n    def upload_files(self):\n        \"\"\"Upload all violation files to Google Drive\"\"\"\n        try:\n            date_str = datetime.strptime(config.PROCESSING_DATE, \"%m/%d/%Y\").strftime(\"%m_%d_%Y\")\n            date_folder = self._get_date_folder(date_str)\n            \n            # Upload video\n            self._upload_file(config.VIDEO_OUTPUT, date_folder['folder_id'], 'video/mp4')\n            \n            # Upload violation images\n            for filename in os.listdir(config.VIOLATION_DIR):\n                if filename.endswith('.jpg'):\n                    filepath = os.path.join(config.VIOLATION_DIR, filename)\n                    self._upload_file(filepath, date_folder['folder_id'], 'image/jpeg')\n            \n            # Share with email\n            self._share_folder(self.root_folder['id'], \"nadiamaged2003@gmail.com\")\n            \n            # Save metadata\n            self._save_metadata()\n            \n            print(\"Upload completed successfully\")\n        except Exception as e:\n            print(f\"Upload failed: {str(e)}\")\n    \n    def _upload_file(self, filepath, folder_id, mime_type):\n        \"\"\"Upload a single file with retry logic\"\"\"\n        filename = os.path.basename(filepath)\n        file_metadata = {\n            'name': filename,\n            'parents': [folder_id]\n        }\n        media = MediaFileUpload(filepath, mimetype=mime_type)\n        \n        for attempt in range(3):\n            try:\n                self.service.files().create(\n                    body=file_metadata,\n                    media_body=media,\n                    fields='id'\n                ).execute()\n                print(f\"Uploaded {filename}\")\n                return\n            except Exception as e:\n                if attempt == 2:\n                    raise\n                time.sleep(5)\n    \n    def _share_folder(self, folder_id, email):\n        \"\"\"Share folder with specified email\"\"\"\n        permission = {\n            'type': 'user',\n            'role': 'writer',\n            'emailAddress': email\n        }\n        self.service.permissions().create(\n            fileId=folder_id,\n            body=permission,\n            fields='id'\n        ).execute()\n        print(f\"Shared folder with {email}\")\n    \n    def _save_metadata(self):\n        \"\"\"Update metadata file in Drive\"\"\"\n        temp_file = 'temp_metadata.json'\n        with open(temp_file, 'w') as f:\n            json.dump(self.metadata, f)\n        \n        query = f\"name='violation_metadata.json' and '{self.root_folder['id']}' in parents\"\n        results = self.service.files().list(q=query, fields=\"files(id)\").execute()\n        \n        if results.get('files'):\n            file_id = results['files'][0]['id']\n            media = MediaFileUpload(temp_file, mimetype='application/json')\n            self.service.files().update(\n                fileId=file_id,\n                media_body=media\n            ).execute()\n        else:\n            file_metadata = {\n                'name': 'violation_metadata.json',\n                'parents': [self.root_folder['id']]\n            }\n            media = MediaFileUpload(temp_file, mimetype='application/json')\n            self.service.files().create(\n                body=file_metadata,\n                media_body=media,\n                fields='id'\n            ).execute()\n        \n        os.remove(temp_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T21:37:23.039692Z","iopub.execute_input":"2025-03-31T21:37:23.039948Z","iopub.status.idle":"2025-03-31T21:37:23.055894Z","shell.execute_reply.started":"2025-03-31T21:37:23.039923Z","shell.execute_reply":"2025-03-31T21:37:23.055104Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===== MAIN EXECUTION =====\nif __name__ == \"__main__\":\n    print(\"Starting safety violation detection...\")\n    \n    # Process video\n    processor = VideoProcessor()\n    processor.process_video()\n    print(\"Video processing completed\")\n    \n    # Upload results\n    uploader = DriveUploader()\n    uploader.upload_files()\n    \n    print(\"Processing complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T21:37:23.056765Z","iopub.execute_input":"2025-03-31T21:37:23.056980Z","iopub.status.idle":"2025-03-31T21:39:03.062927Z","shell.execute_reply.started":"2025-03-31T21:37:23.056961Z","shell.execute_reply":"2025-03-31T21:39:03.061947Z"}},"outputs":[],"execution_count":null}]}